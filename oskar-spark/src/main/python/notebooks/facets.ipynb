{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Facets example**\n",
    "This Jupyter script is an example for a use case of the Pyoskar API, which works in perfect combination with Pyspark in order to provide a genomic analysis tool. On this example we show some ways that could be of interest to start using the Facets functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to go through this step before we start using Pyoskar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyoskar.core import Oskar\n",
    "from pyoskar.sql import *\n",
    "from pyoskar.analysis import *\n",
    "from pyspark.sql.functions import col, udf, count, explode, concat, when, expr\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "oskar = Oskar(spark)\n",
    "df = oskar.load(\"/home/roldanx/appl/oskar/oskar-spark/src/test/resources/platinum_chr22.small.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Facet\n",
    "Now that we have loaded our data, we start with an easy facet. This example executes the classics \"groupBy\" and \"count\" upon our dataframe basing on the variant types and the genes that contains them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| type|count|\n",
      "+-----+-----+\n",
      "|INDEL|  106|\n",
      "|  SNV|  894|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oskar.facet(df, \"type\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       gene|count|\n",
      "+-----------+-----+\n",
      "|    ABCD1P4|    2|\n",
      "|  ABHD17AP4|    2|\n",
      "| AC000029.1|    1|\n",
      "| AC000041.8|    2|\n",
      "| AC000067.1|    1|\n",
      "|AC000068.10|    1|\n",
      "| AC000068.5|    1|\n",
      "| AC000089.3|    1|\n",
      "| AC002472.1|    4|\n",
      "|AC004019.10|    1|\n",
      "+-----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oskar.facet(df, \"gene\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include Facet\n",
    "This next example goes a bit further and als applies a filtering based on the values we explicit in the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   gene|count|\n",
      "+-------+-----+\n",
      "|BCL2L13|    8|\n",
      "|  CECR2|   11|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oskar.facet(df, \"gene[BCL2L13,CECR2]\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Range facet\n",
    "Using a similar sintax as with \"Include facets\" but dealing with quantitative fields instead of qualitative we find that we can apply facets by range, where we can determine both upper and downer thresholds as well as the step. For this example we have chosen the \"phylop\" conservation score but other conservation, functional and substitution scores are available too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|phylopRange|count|\n",
      "+-----------+-----+\n",
      "|       -4.0|    3|\n",
      "|       -3.0|   12|\n",
      "|       -2.0|   55|\n",
      "|       -1.0|  171|\n",
      "|        0.0|  681|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oskar.facet(df, \"phylop[-5..0]:1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation facet\n",
    "We may want to check whether the compounds of all variants have historically been well conservated or otherways have notably evolved. For this task we could use the aggregation facets, with substitutes the default \"count\" function for another one we decide among this ones: average[avg], sumatory[sum], square sumatory[sumsq], percentiles[percentile] or set of values[unique]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|         sum(gerp)|count|\n",
      "+------------------+-----+\n",
      "|-351.8712293113349| 1000|\n",
      "+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oskar.facet(df, \"sum(gerp)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------+-----+\n",
      "|percentile(gerp)                                                                       |count|\n",
      "+---------------------------------------------------------------------------------------+-----+\n",
      "|[-2.152000093460083, -0.6257500052452087, 0.0, 0.14900000393390656, 0.7430999755859375]|1000 |\n",
      "+---------------------------------------------------------------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oskar.facet(df, \"percentile(gerp)\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested facets\n",
    "The last feature we find available for our facet queries is nesting, which allows us to concatenate gruops and reach complex studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------------------+-----+\n",
      "|biotype                |ct                  |count|\n",
      "+-----------------------+--------------------+-----+\n",
      "|nonsense_mediated_decay|splice_donor_variant|1    |\n",
      "|processed_transcript   |splice_donor_variant|1    |\n",
      "|protein_coding         |splice_donor_variant|1    |\n",
      "|retained_intron        |splice_donor_variant|1    |\n",
      "+-----------------------+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oskar.facet(df, \"biotype>>ct[splice_donor_variant]\").show(100, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerp + PF ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------------+----+---------+-----------+-----+\n",
      "|cadd_rawRange|biotype                |type|gerpRange|gene       |count|\n",
      "+-------------+-----------------------+----+---------+-----------+-----+\n",
      "|0.0          |IG_V_gene              |SNV |-1.0     |IGLV3-12   |1    |\n",
      "|0.0          |antisense              |SNV |-1.0     |CTA-85E5.10|1    |\n",
      "|0.0          |antisense              |SNV |-1.0     |EIF4ENIF1  |1    |\n",
      "|0.0          |antisense              |SNV |-0.5     |CTA-85E5.10|1    |\n",
      "|0.0          |antisense              |SNV |0.0      |EIF4ENIF1  |1    |\n",
      "|0.0          |antisense              |SNV |0.5      |CTA-85E5.10|1    |\n",
      "|0.0          |nonsense_mediated_decay|SNV |-1.0     |EIF4ENIF1  |1    |\n",
      "|0.0          |nonsense_mediated_decay|SNV |0.0      |EIF4ENIF1  |1    |\n",
      "|0.0          |nonsense_mediated_decay|SNV |2.5      |EIF4ENIF1  |1    |\n",
      "|0.0          |processed_transcript   |SNV |2.5      |EIF4ENIF1  |1    |\n",
      "|0.0          |protein_coding         |SNV |-1.0     |EIF4ENIF1  |1    |\n",
      "|0.0          |protein_coding         |SNV |0.0      |EIF4ENIF1  |1    |\n",
      "|0.0          |protein_coding         |SNV |0.5      |CTA-85E5.10|1    |\n",
      "|0.0          |protein_coding         |SNV |2.5      |EIF4ENIF1  |1    |\n",
      "|0.0          |retained_intron        |SNV |0.5      |CTA-85E5.10|1    |\n",
      "|0.0          |retained_intron        |SNV |2.5      |EIF4ENIF1  |1    |\n",
      "+-------------+-----------------------+----+---------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oskar.facet(df, \"cadd_raw[-100..100]:10>>biotype>>type>>gerp[-10..10]:0.5>>gene[CNN2P1,EIF4ENIF1,IGLV3-12,CTA-85E5.10]\").show(100, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
