{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Variant filtering example**\n",
    "This Jupyter script is an example for a use case of the Oskar API, which works in perfect combination with Pyspark in order to provide a genomic analysis tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we need to import the modules that contain the Oskar API as well as the Spark ones. Also we need to create a new instance of the Oskar object, from which depends the whole functionality, and load our data as \"df\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional: Create a Temporary View case you plan to acces the data folder from SQL.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyoskar.core import Oskar\n",
    "from pyoskar.spark.sql import *\n",
    "from pyoskar.spark.analysis import *\n",
    "from pyspark.sql.functions import col, udf, count, explode, concat, when, expr\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "oskar = Oskar(spark)\n",
    "df = oskar.load(\"/home/roldanx/appl/oskar/oskar-spark/src/test/resources/platinum_chr22.small.parquet\")\n",
    "df.createOrReplaceTempView(\"platinum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region filter\n",
    "First of all we will execute a variant filtering based on a restricting zone, which in this example we chose as the 22th chromosome and the nucleotides between 17.000.000 and 17.500.000 position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+--------+--------+\n",
      "|             id|chromosome|   start|     end|\n",
      "+---------------+----------+--------+--------+\n",
      "|22:17001352:C:G|        22|17001352|17001352|\n",
      "|22:17002352:C:A|        22|17002352|17002352|\n",
      "|22:17004097:G:A|        22|17004097|17004097|\n",
      "|22:17011943:G:C|        22|17011943|17011943|\n",
      "|22:17012760:G:A|        22|17012760|17012760|\n",
      "|22:17013084:C:T|        22|17013084|17013084|\n",
      "|22:17013900:A:G|        22|17013900|17013900|\n",
      "|22:17019574:C:A|        22|17019574|17019574|\n",
      "|22:17030949:T:C|        22|17030949|17030949|\n",
      "|22:17034810:T:C|        22|17034810|17034810|\n",
      "+---------------+----------+--------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pyspark\n",
    "df.select(\"id\", \"chromosome\", \"start\", \"end\").filter(df.chromosome == 22).filter(df.start > 17000000).filter(df.end < 17500000).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+--------+--------+\n",
      "|             id|chromosome|   start|     end|\n",
      "+---------------+----------+--------+--------+\n",
      "|22:17001352:C:G|        22|17001352|17001352|\n",
      "|22:17002352:C:A|        22|17002352|17002352|\n",
      "|22:17004097:G:A|        22|17004097|17004097|\n",
      "|22:17011943:G:C|        22|17011943|17011943|\n",
      "|22:17012760:G:A|        22|17012760|17012760|\n",
      "|22:17013084:C:T|        22|17013084|17013084|\n",
      "|22:17013900:A:G|        22|17013900|17013900|\n",
      "|22:17019574:C:A|        22|17019574|17019574|\n",
      "|22:17030949:T:C|        22|17030949|17030949|\n",
      "|22:17034810:T:C|        22|17034810|17034810|\n",
      "+---------------+----------+--------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\"SELECT id,chromosome,start,end FROM platinum WHERE chromosome =='22' AND start > 17000000 AND end < 17500000\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene filter\n",
    "On the second place we would like to execute a filtering which ties up the variants attached to a concrete gene. \"NBEAP3\" was chosen as the target. Here we start preciating the functionality of Oskar API: \"genes\" field is automatically located and easily accesed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "|             id|               genes|\n",
      "+---------------+--------------------+\n",
      "|22:16096040:G:A|            [NBEAP3]|\n",
      "|22:16099957:C:T|            [NBEAP3]|\n",
      "|22:16100462:A:G|            [NBEAP3]|\n",
      "|22:16105660:G:A|            [NBEAP3]|\n",
      "|22:16112391:G:A|            [NBEAP3]|\n",
      "|22:16114913:A:T|            [NBEAP3]|\n",
      "|22:16127471:A:-|[LA16c-60H5.7, NB...|\n",
      "+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.id, genes(\"annotation\").alias(\"genes\")).filter(array_contains(\"genes\", \"NBEAP3\")).show()\n",
    "# spark.sql(\"SELECT id,genes(annotation) FROM platinum WHERE CONTAINS(genes(annotation), 'NBEAP3')\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genotype filter\n",
    "In this case we would like to show the way we could get the genotypes corresponding to any sample with our \"sampleDataField\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|NA12877|\n",
      "+-------+\n",
      "|    ./.|\n",
      "|    0/1|\n",
      "|    ./.|\n",
      "|    0/1|\n",
      "|    ./.|\n",
      "|    ./.|\n",
      "|    ./.|\n",
      "|    0/1|\n",
      "|    0/1|\n",
      "|    0/1|\n",
      "+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark\n",
    "df.select(sample_data_field(col(\"studies\"), 'NA12877', 'GT').alias(\"NA12877\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|NA12877|\n",
      "+-------+\n",
      "|    ./.|\n",
      "|    0/1|\n",
      "|    ./.|\n",
      "|    0/1|\n",
      "|    ./.|\n",
      "|    ./.|\n",
      "|    ./.|\n",
      "|    0/1|\n",
      "|    0/1|\n",
      "|    0/1|\n",
      "+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\"SELECT sample_data_field(studies, 'NA12877', 'GT')  AS NA12877 FROM platinum\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Frequency filter\n",
    "Finally we want to filter our dataframe by using PF field, so we just type \"population_frequency\" and specify the field were we can acces it, the ID of the concrete study we would like to check, and the target population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "|             id|  GNOMAD_GENOMES:ALL|\n",
      "+---------------+--------------------+\n",
      "|22:16054454:C:T| 0.07566695660352707|\n",
      "|22:16065809:T:C| 0.14594951272010803|\n",
      "|22:16077310:T:A|  0.2338419109582901|\n",
      "|22:16080499:A:G|                 0.0|\n",
      "|22:16084621:T:C|                 0.0|\n",
      "|22:16091610:G:T|0.003129890421405...|\n",
      "|22:16096040:G:A|                 0.0|\n",
      "|22:16099957:C:T|  0.6782668232917786|\n",
      "|22:16100462:A:G|                 0.0|\n",
      "|22:16105660:G:A| 0.12387744337320328|\n",
      "+---------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.id, population_frequency(\"annotation\", \"GNOMAD_GENOMES\", \"ALL\").alias(\"GNOMAD_GENOMES:ALL\"))\\\n",
    "    .filter(population_frequency(\"annotation\", \"GNOMAD_GENOMES\", \"ALL\") != 0).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, if we are interested in getting all the Population Frequencies available, we can use this other method named \"population_frequency_as_map\" which will return the whole set as a dictionary format. Then we could apply \"explode\" and convert that dictionary into a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------------+\n",
      "|               study|populationFrequenciesDF|\n",
      "+--------------------+-----------------------+\n",
      "|  GNOMAD_GENOMES:OTH|     0.6896551847457886|\n",
      "|  GNOMAD_GENOMES:ALL|     0.6782668232917786|\n",
      "|  GNOMAD_GENOMES:AFR|     0.6747621297836304|\n",
      "|  GNOMAD_GENOMES:NFE|     0.6699579954147339|\n",
      "| GNOMAD_GENOMES:MALE|      0.682662844657898|\n",
      "|  GNOMAD_GENOMES:FIN|     0.6726332306861877|\n",
      "|  GNOMAD_GENOMES:EAS|     0.9523809552192688|\n",
      "|  GNOMAD_GENOMES:ASJ|     0.5721649527549744|\n",
      "|GNOMAD_GENOMES:FE...|     0.6727412939071655|\n",
      "|  GNOMAD_GENOMES:AMR|     0.6950549483299255|\n",
      "+--------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PF = df.select(df.id, population_frequency_as_map(\"annotation\").alias(\"populationFrequencies\"))\\\n",
    "    .filter(df.id == \"22:16099957:C:T\")\n",
    "PF.select(explode(PF.populationFrequencies).alias(\"study\", \"populationFrequenciesDF\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
